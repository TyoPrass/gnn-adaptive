# -*- coding: utf-8 -*-
"""HGT(Heterogeneous Graph Transformer).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Im1uu--l58Dis-8Qwzx4OWqqeHkTqOT

# Library
"""

# !pip install dgl torchdata -f https://data.dgl.ai/wheels/cu118/repo.html

# newewst version to long response
# !pip install torch

# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric networkx -f https://data.pyg.org/whl/torch-2.0.0+cu118.html

!pip uninstall -y torch torchvision torchaudio torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric
!pip install torch==2.2.2+cu118 torchvision==0.17.2+cu118 torchaudio==2.2.2 --extra-index-url https://download.pytorch.org/whl/cu118
!pip install torch-geometric==2.5.3 torch-scatter -f https://data.pyg.org/whl/torch-2.2.2+cu118.html
!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.2+cu118.html
!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.2.2+cu118.html
!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.2+cu118.html

import pandas as pd
import numpy as np
import random

import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.pyplot as plt

import networkx as nx

import torch
from torch_geometric.nn import HANConv, GCNConv, RGCNConv, HGTConv, Linear
# SAGEConv, GATConv, GINConv
from torch_geometric.data import HeteroData, Data
from torch_geometric.transforms import AddMetaPaths
from torch_geometric.utils import from_networkx
import torch.nn as nn
import torch.nn.functional as F

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from google.colab import sheets

# Data modul: (modul_id, nama_modul, level_kesulitan, kelas, deskriptif)
modul_data = [
    ("M1", "Ruang Lingkup Biologi", 1, 10, "Mempelajari cabang-cabang biologi, metode ilmiah, dan objek studi biologi."),
    ("M2", "Keanekaragaman Hayati", 1, 10, "Mengkaji keanekaragaman makhluk hidup, klasifikasi, dan kunci determinasi."),
    ("M3", "Virus", 2, 10, "Mempelajari struktur, replikasi, dan peran virus dalam kehidupan."),
    ("M4", "Bakteri", 2, 10, "Mengkaji struktur, klasifikasi, dan peran bakteri."),
    ("M5", "Protista", 2, 10, "Mempelajari kelompok protista, ciri-ciri, dan peranannya."),
    ("M6", "Jamur", 2, 10, "Mengkaji struktur, klasifikasi, dan peran jamur."),
    ("M7", "Plantae (Tumbuhan)", 3, 10, "Mempelajari struktur, fisiologi, dan klasifikasi tumbuhan."),
    ("M8", "Ekosistem dan Perubahan Lingkungan", 2, 10, "Mengkaji komponen ekosistem, interaksi antar organisme, dan dampak perubahan lingkungan."),
    ("M9", "Daur Biogeokimia", 2, 10, "Mempelajari siklus unsur-unsur kimia dalam ekosistem."),

    ("M10", "Struktur dan Fungsi Sel", 2, 11, "Mempelajari struktur sel prokariotik dan eukariotik, serta organel sel."),
    ("M11", "Sistem Organ Hewan", 3, 11, "Mempelajari berbagai sistem organ pada hewan, seperti sistem pencernaan, pernapasan, sirkulasi, ekskresi, saraf, indra, endokrin, rangka, dan otot."),
    ("M12", "Pertumbuhan dan Perkembangan", 3, 11, "Mempelajari pertumbuhan dan perkembangan pada tumbuhan dan hewan."),
    ("M13", "Sistem Imun", 3, 11, "Mempelajari mekanisme pertahanan tubuh terhadap infeksi."),
    ("M14", "Sistem Hormon", 3, 11, "Mempelajari sistem hormon pada tumbuhan dan hewan."),

    ("M15", "Genetika", 3, 12, "Mempelajari materi genetik (DNA dan RNA), replikasi, transkripsi, translasi, serta pewarisan sifat."),
    ("M16", "Evolusi", 3, 12, "Mempelajari teori evolusi, mekanisme evolusi, dan bukti-bukti evolusi."),
    ("M17", "Bioteknologi", 3, 12, "Mempelajari prinsip-prinsip bioteknologi, aplikasi bioteknologi dalam berbagai bidang, dan etika bioteknologi."),

    ("M18", "Mikrobiologi", 2, 12, "Mempelajari mikroorganisme, seperti bakteri, virus, dan fungi, serta perannya dalam kehidupan."),
    ("M19", "Fisiologi dan Anatomi", 3, 12, "Mempelajari fungsi organ dan sistem organ pada makhluk hidup."),
    ("M20", "Ekologi", 2, 12, "Mempelajari hubungan antar organisme dan lingkungannya."),
]

# Data egde: (src_modul, dst_modul, edge_type)
# edge_data = [
#     ("M1", "M2", "prasyarat"),
#     ("M2", "M3", "prasyarat"),
#     ("M2", "M4", "prasyarat"),
#     ("M2", "M5", "prasyarat"),
#     ("M3", "M18", "prasyarat"),
#     ("M4", "M18", "prasyarat"),
#     ("M5", "M6", "prasyarat"),
#     ("M6", "M7", "prasyarat"),
#     ("M1", "M8", "prasyarat"),
#     ("M8", "M9", "prasyarat"),
#     ("M7", "M12", "prasyarat"),
#     ("M10", "M11", "prasyarat"),
#     ("M10", "M19", "prasyarat"),
#     ("M10", "M13", "prasyarat"),
#     ("M10", "M14", "prasyarat"),
#     ("M11", "M19", "prasyarat"),
#     ("M10", "M15", "prasyarat"),
#     ("M15", "M16", "prasyarat"),
#     ("M15", "M17", "prasyarat"),
#     ("M9", "M20", "prasyarat"),
#     ("M8", "M20", "prasyarat"),
# ]
edge_data = [
    # Kelas 10
    ("M1", "M2", "prasyarat"),  # Ruang Lingkup -> Keanekaragaman
    ("M2", "M3", "prasyarat"),  # Keanekaragaman -> Virus
    ("M2", "M4", "prasyarat"),  # Keanekaragaman -> Bakteri
    ("M2", "M5", "prasyarat"),  # Keanekaragaman -> Protista
    ("M5", "M6", "prasyarat"),  # Protista -> Jamur
    ("M6", "M7", "prasyarat"),  # Jamur -> Plantae
    ("M1", "M8", "prasyarat"),  # Ruang Lingkup -> Ekosistem
    ("M8", "M9", "prasyarat"),  # Ekosistem -> Daur Biogeokimia

    # Kelas 11
    ("M3", "M10", "prasyarat"),  # Virus -> Sel
    ("M4", "M10", "prasyarat"),  # Bakteri -> Sel
    ("M10", "M11", "prasyarat"), # Sel -> Sistem Organ
    ("M10", "M13", "prasyarat"), # Sel -> Sistem Imun
    ("M10", "M14", "prasyarat"), # Sel -> Sistem Hormon
    ("M11", "M19", "prasyarat"), # Sistem Organ -> Fisiologi

    # Kelas 12
    ("M10", "M15", "prasyarat"), # Sel -> Genetika
    ("M15", "M16", "prasyarat"), # Genetika -> Evolusi
    ("M15", "M17", "prasyarat"), # Genetika -> Bioteknologi
    ("M3", "M18", "prasyarat"),  # Virus -> Mikrobiologi
    ("M4", "M18", "prasyarat"),  # Bakteri -> Mikrobiologi
    ("M8", "M20", "prasyarat"),  # Ekosistem -> Ekologi
]

modul_tujuan_user = [
    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10',
    'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M19', 'M20'
]

self_estimator = {
    'M1': 80, 'M2': 70, 'M3': 60, 'M4': 55, 'M5': 60,
    'M6': 40, 'M7': 30, 'M8': 75, 'M9': 60, 'M10': 70,
    'M11': 65, 'M12': 50, 'M13': 40, 'M14': 45, 'M15': 35,
    'M16': 20, 'M17': 30, 'M18': 50, 'M19': 30, 'M20': 55
} # Self-estimation siswa untuk tiap modul (0â€“100)

jawaban_benar = {
    'M1': 5, 'M2': 4, 'M3': 2, 'M4': 2, 'M5': 3,
    'M6': 1, 'M7': 0, 'M8': 4, 'M9': 3, 'M10': 4,
    'M11': 3, 'M12': 2, 'M13': 1, 'M14': 2, 'M15': 1,
    'M16': 0, 'M17': 1, 'M18': 2, 'M19': 1, 'M20': 2
} # Jumlah jawaban benar siswa (max 5 soal per modul)

"""# Preprocesing"""

# 1. Normalisasi data
def normalize_data():
    kinerja = {m: score/5 for m, score in jawaban_benar.items()}
    estimator = {m: score/100 for m, score in self_estimator.items()}
    knowledge = {m: ((2*kinerja[m]) + estimator[m])/3 for m in kinerja}
    return kinerja, estimator, knowledge

kinerja, estimator, knowledge = normalize_data()

# 2. Hitung bobot prasyarat
alpha = 1 # Alpha juga bisa diubah

def calculate_prerequisite_weights():
    modul_level = {row[0]: row[2] for row in modul_data}
    weighted_edges = []
    for src, dst, etype in edge_data:
        weight = 1 / (modul_level[dst] + alpha)  # Rumus bobot
        weighted_edges.append((src, dst, etype, weight))
    return weighted_edges

weighted_edges = calculate_prerequisite_weights()

# 3. Buat edge user-modul
def create_user_edges():
    user_edges = []
    for modul in modul_tujuan_user:
        user_edges.append(('user', modul, 'kinerja', kinerja[modul]))
        user_edges.append(('user', modul, 'estimasi', estimator[modul]))
    return user_edges

user_edges = create_user_edges()

"""# Seed for consistency data"""

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

"""# Graph Construct"""

df_nodes = pd.DataFrame(modul_data, columns=["modul_id", "nama_modul", "level_kesulitan", "kelas", "deskripsi"])
df_edges = pd.DataFrame(weighted_edges, columns=["src", "dst", "type", "weight"])

G = nx.DiGraph()

# Tambahkan node
for _, row in df_nodes.iterrows():
    G.add_node(row['modul_id'],
               label=row['nama_modul'],
               level=row['level_kesulitan'],
               kelas=row['kelas'],
               node_type='modul')

    G.add_node('user', label='User', node_type='user')

# Tambahkan edge
for _, row in df_edges.iterrows():
    G.add_edge(row['src'], row['dst'],
               type=row['type'],
               weight=row['weight'])

for src, dst, etype, val in user_edges:
    G.add_edge(src, dst, type=etype, value=val)

def visualize_graph():
    plt.figure(figsize=(20, 15))

    # Position nodes by kelas
    pos = {}
    kelas_groups = {}
    for node in G.nodes():
        if node == 'user':
            kelas = 0
        else:
            kelas = G.nodes[node]['kelas']

        if kelas not in kelas_groups:
            kelas_groups[kelas] = []
        kelas_groups[kelas].append(node)

    # Arrange nodes in layers
    for i, kelas in enumerate(sorted(kelas_groups.keys(), reverse=True)):
        nodes = kelas_groups[kelas]
        for j, node in enumerate(nodes):
            pos[node] = (j - len(nodes)/2, -i)

    # Node colors
    node_color_map = []
    for node in G.nodes():
        if node == 'user':
            node_color_map.append('gray') # Assign a specific color for the user node
        else:
            # Use the numerical 'kelas' value for modules to map to a colormap
            node_color_map.append(G.nodes[node]['kelas'])

    # Draw nodes - handle user node color separately
    modul_nodes = [n for n in G.nodes() if n != 'user']
    user_node = 'user'

    # Create a list of color values for modul nodes based on 'kelas'
    modul_colors = [G.nodes[n]['kelas'] for n in modul_nodes]

    # Draw modul nodes using a colormap
    nx.draw_networkx_nodes(G, pos, nodelist=modul_nodes, node_color=modul_colors, cmap=plt.cm.Set3, node_size=1000)

    # Draw user node with a specific color
    nx.draw_networkx_nodes(G, pos, nodelist=[user_node], node_color='gray', node_size=1000)


    # Draw edges with different styles
    prerequisite_edges = [(u, v) for u, v, d in G.edges(data=True) if d['type'] == 'prasyarat']
    performance_edges = [(u, v) for u, v, d in G.edges(data=True) if d['type'] == 'kinerja']
    estimate_edges = [(u, v) for u, v, d in G.edges(data=True) if d['type'] == 'estimasi']

    nx.draw_networkx_edges(G, pos, edgelist=prerequisite_edges,
                          edge_color='black', arrows=True, arrowstyle='->')
    nx.draw_networkx_edges(G, pos, edgelist=performance_edges,
                          edge_color='red', style='dashed')
    nx.draw_networkx_edges(G, pos, edgelist=estimate_edges,
                          edge_color='blue', style='dotted')

    nx.draw_networkx_labels(G, pos, labels=nx.get_node_attributes(G, 'label'), font_size=8)

    plt.title("Struktur Modul dengan Interaksi User", fontsize=16)
    plt.axis('off')
    plt.show()

visualize_graph()

"""# HGT"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Tuple, Optional

class HeteroGraph:
    """Simple heterogeneous graph representation"""
    def __init__(self, node_types: List[str], edge_types: List[str]):
        self.node_types = node_types
        self.edge_types = edge_types
        self.nodes = {ntype: [] for ntype in node_types}
        self.edges = {etype: [] for etype in edge_types}
        self.node_mapping = {}

    def add_node(self, node_id: str, node_type: str):
        idx = len(self.nodes[node_type])
        self.nodes[node_type].append(node_id)
        self.node_mapping[node_id] = (node_type, idx)

    def add_edge(self, src: str, dst: str, edge_type: str):
        src_type, src_idx = self.node_mapping[src]
        dst_type, dst_idx = self.node_mapping[dst]
        self.edges[edge_type].append((src_type, src_idx, dst_type, dst_idx))

    def get_edge_index(self, edge_type: str, src_type: str, dst_type: str):
        edges = []
        for s_type, s_idx, d_type, d_idx in self.edges[edge_type]:
            if s_type == src_type and d_type == dst_type:
                edges.append([s_idx, d_idx])
        return torch.LongTensor(edges).t() if edges else torch.LongTensor([[], []])

class HGTLayer(nn.Module):
    def __init__(self, in_dim: int, out_dim: int, node_types: List[str],
                 edge_types: List[str], n_heads: int = 4, dropout: float = 0.1):
        super(HGTLayer, self).__init__()
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.node_types = node_types
        self.edge_types = edge_types
        self.n_heads = n_heads
        self.d_k = out_dim // n_heads

        # Node type specific transformations
        self.node_transform = nn.ModuleDict({
            ntype: nn.Linear(in_dim, out_dim) for ntype in node_types
        })

        # Attention mechanisms for each edge type
        self.attention = nn.ModuleDict()
        for etype in edge_types:
            self.attention[etype] = nn.ModuleDict({
                'W_Q': nn.Linear(out_dim, out_dim),
                'W_K': nn.Linear(out_dim, out_dim),
                'W_V': nn.Linear(out_dim, out_dim),
                'W_O': nn.Linear(out_dim, out_dim)
            })

        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.ModuleDict({
            ntype: nn.LayerNorm(out_dim) for ntype in node_types
        })

    def message_passing(self, h_transformed: Dict[str, torch.Tensor],
                       graph: HeteroGraph, edge_type: str,
                       src_type: str, dst_type: str) -> Optional[torch.Tensor]:
        edge_index = graph.get_edge_index(edge_type, src_type, dst_type)

        if edge_index.size(1) == 0:
            return None

        src_feat = h_transformed[src_type]
        dst_feat = h_transformed[dst_type]

        # Multi-head attention
        Q = self.attention[edge_type]['W_Q'](dst_feat).view(-1, self.n_heads, self.d_k)
        K = self.attention[edge_type]['W_K'](src_feat).view(-1, self.n_heads, self.d_k)
        V = self.attention[edge_type]['W_V'](src_feat).view(-1, self.n_heads, self.d_k)

        src_indices = edge_index[0]
        dst_indices = edge_index[1]

        Q_edges = Q[dst_indices]
        K_edges = K[src_indices]
        V_edges = V[src_indices]

        # Compute attention weights
        scores = torch.sum(Q_edges * K_edges, dim=-1) / np.sqrt(self.d_k)
        attn_weights = F.softmax(scores, dim=0)
        attn_weights = self.dropout(attn_weights.unsqueeze(-1))

        # Apply attention
        attn_output = attn_weights * V_edges
        attn_output = attn_output.view(-1, self.out_dim)

        # Aggregate messages to destination nodes
        messages = torch.zeros(dst_feat.size(0), self.out_dim, device=dst_feat.device)
        for i, dst_idx in enumerate(dst_indices):
            messages[dst_idx] += attn_output[i]

        messages = self.attention[edge_type]['W_O'](messages)
        return messages

    def forward(self, graph: HeteroGraph, h_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        # Transform node features
        h_transformed = {}
        for ntype in self.node_types:
            if ntype in h_dict and h_dict[ntype].size(0) > 0:
                h_transformed[ntype] = self.node_transform[ntype](h_dict[ntype])

        # Collect messages for each node type
        messages = {ntype: [] for ntype in self.node_types}

        # Message passing for each edge type and node type combination
        for edge_type in self.edge_types:
            for src_type in self.node_types:
                for dst_type in self.node_types:
                    if src_type in h_transformed and dst_type in h_transformed:
                        msg = self.message_passing(h_transformed, graph, edge_type, src_type, dst_type)
                        if msg is not None:
                            messages[dst_type].append(msg)

        # Aggregate messages and apply residual connection
        h_out = {}
        for ntype in self.node_types:
            if ntype in h_transformed:
                if messages[ntype]:
                    aggregated = torch.stack(messages[ntype]).mean(dim=0)
                    h_out[ntype] = self.layer_norm[ntype](h_transformed[ntype] + aggregated)
                else:
                    h_out[ntype] = h_transformed[ntype]

        return h_out

class HGTModel(nn.Module):
    def __init__(self, node_types: List[str], edge_types: List[str],
                 in_dim: int, hidden_dim: int, out_dim: int, n_layers: int = 2, n_heads: int = 4):
        super(HGTModel, self).__init__()
        self.node_types = node_types
        self.edge_types = edge_types
        self.n_layers = n_layers

        # Input embedding for each node type
        self.embedding = nn.ModuleDict({
            ntype: nn.Linear(in_dim, hidden_dim) for ntype in node_types
        })

        # HGT layers
        self.hgt_layers = nn.ModuleList([
            HGTLayer(hidden_dim, hidden_dim, node_types, edge_types, n_heads)
            for _ in range(n_layers)
        ])

        # Output projection
        self.output_projection = nn.ModuleDict({
            ntype: nn.Linear(hidden_dim, out_dim) for ntype in node_types
        })

    def forward(self, graph: HeteroGraph, node_features: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        # Initial embedding
        h = {}
        for ntype in self.node_types:
            if ntype in node_features and node_features[ntype].size(0) > 0:
                h[ntype] = self.embedding[ntype](node_features[ntype])

        # HGT layers
        for layer in self.hgt_layers:
            h = layer(graph, h)

        # Output projection
        output = {}
        for ntype in self.node_types:
            if ntype in h:
                output[ntype] = self.output_projection[ntype](h[ntype])

        return output

def convert_networkx_to_hetero(G: nx.Graph) -> Tuple[HeteroGraph, Dict[str, torch.Tensor]]:
    """Convert NetworkX graph to custom heterogeneous graph"""
    node_types = ['user', 'modul']
    edge_types = ['prasyarat', 'kinerja', 'estimasi']

    # Create heterogeneous graph
    hetero_graph = HeteroGraph(node_types, edge_types)
    node_features = {'user': [], 'modul': []}

    # Add nodes
    for node in G.nodes():
        if node == 'user':
            hetero_graph.add_node(node, 'user')
            # User features: [user_indicator, avg_performance, avg_estimation]
            avg_perf = np.mean(list(kinerja.values()))
            avg_est = np.mean(list(estimator.values()))
            node_features['user'].append([1.0, avg_perf, avg_est])
        else:
            hetero_graph.add_node(node, 'modul')
            kelas = G.nodes[node]['kelas']
            level = G.nodes[node]['level']
            # Module features: [module_indicator, class_level, difficulty_level]
            node_features['modul'].append([0.0, float(kelas)/12, float(level)/3])

    # Add edges
    for u, v, data in G.edges(data=True):
        edge_type = data.get('type', 'prasyarat')
        if edge_type in edge_types:
            hetero_graph.add_edge(u, v, edge_type)

    # Convert features to tensors
    feature_tensors = {}
    for ntype in node_types:
        if node_features[ntype]:
            feature_tensors[ntype] = torch.FloatTensor(node_features[ntype])
        else:
            feature_tensors[ntype] = torch.FloatTensor([[0.0, 0.0, 0.0]])

    return hetero_graph, feature_tensors

def train_hgt_model(G: nx.Graph, epochs: int = 100, lr: float = 0.01):
    """Train HGT model on the graph"""
    print("Converting graph to heterogeneous format...")
    hetero_graph, node_features = convert_networkx_to_hetero(G)

    # Initialize model
    node_types = ['user', 'modul']
    edge_types = ['prasyarat', 'kinerja', 'estimasi']

    model = HGTModel(
        node_types=node_types,
        edge_types=edge_types,
        in_dim=3,  # feature dimension
        hidden_dim=64,
        out_dim=32,  # embedding dimension
        n_layers=2
    )

    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    print("Training HGT model...")
    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()

        # Forward pass
        output = model(hetero_graph, node_features)

        # Self-supervised loss
        loss = 0

        # Reconstruction loss for user
        if 'user' in output:
            user_target = node_features['user'][:, :2]  # Use first 2 features
            user_pred = output['user'][:, :2]
            loss += F.mse_loss(user_pred, user_target)

        # Module similarity loss based on class and difficulty
        if 'modul' in output and output['modul'].size(0) > 1:
            modul_emb = output['modul']
            modul_features = node_features['modul']

            # Create similarity targets based on class and difficulty
            similarity_target = torch.mm(modul_features[:, 1:], modul_features[:, 1:].t())
            similarity_pred = torch.mm(modul_emb, modul_emb.t())
            similarity_pred = torch.sigmoid(similarity_pred)

            loss += F.mse_loss(similarity_pred, similarity_target)

        # Edge prediction loss
        edge_loss = 0
        for edge_type in edge_types:
            for src_type in node_types:
                for dst_type in node_types:
                    edge_index = hetero_graph.get_edge_index(edge_type, src_type, dst_type)
                    if edge_index.size(1) > 0 and src_type in output and dst_type in output:
                        src_emb = output[src_type]
                        dst_emb = output[dst_type]

                        # Positive edges
                        pos_src = src_emb[edge_index[0]]
                        pos_dst = dst_emb[edge_index[1]]
                        pos_scores = torch.sum(pos_src * pos_dst, dim=1)

                        # Negative sampling
                        if src_emb.size(0) > 1 and dst_emb.size(0) > 1:
                            num_neg = min(edge_index.size(1), 5)
                            neg_src_idx = torch.randint(0, src_emb.size(0), (num_neg,))
                            neg_dst_idx = torch.randint(0, dst_emb.size(0), (num_neg,))
                            neg_src = src_emb[neg_src_idx]
                            neg_dst = dst_emb[neg_dst_idx]
                            neg_scores = torch.sum(neg_src * neg_dst, dim=1)

                            # BCE loss
                            pos_labels = torch.ones(pos_scores.size(0))
                            neg_labels = torch.zeros(neg_scores.size(0))

                            all_scores = torch.cat([pos_scores, neg_scores])
                            all_labels = torch.cat([pos_labels, neg_labels])

                            edge_loss += F.binary_cross_entropy_with_logits(all_scores, all_labels)

        total_loss = loss + 0.1 * edge_loss
        total_loss.backward()
        optimizer.step()

        if epoch % 20 == 0:
            print(f'Epoch {epoch}, Loss: {total_loss.item():.4f}')

    return model, hetero_graph, node_features

def get_module_recommendations(model: HGTModel, hetero_graph: HeteroGraph,
                             node_features: Dict[str, torch.Tensor],
                             top_k: int = 10) -> List[Tuple[str, float, Dict]]:
    """Generate module recommendations for user"""
    model.eval()

    with torch.no_grad():
        embeddings = model(hetero_graph, node_features)

        if 'user' not in embeddings or 'modul' not in embeddings:
            return []

        user_emb = embeddings['user'][0]
        modul_embs = embeddings['modul']

        # Calculate similarity scores
        similarities = torch.cosine_similarity(user_emb.unsqueeze(0), modul_embs, dim=1)

        # Get module information
        modul_nodes = hetero_graph.nodes['modul']

        # Create recommendations with module details
        recommendations = []
        modul_dict = {row[0]: row for row in modul_data}

        for i, (modul_id, score) in enumerate(zip(modul_nodes, similarities)):
            if modul_id in modul_dict:
                modul_info = modul_dict[modul_id]
                module_detail = {
                    'nama': modul_info[1],
                    'level_kesulitan': modul_info[2],
                    'kelas': modul_info[3],
                    'deskripsi': modul_info[4],
                    'knowledge_score': knowledge.get(modul_id, 0),
                    'performance_score': kinerja.get(modul_id, 0),
                    'estimation_score': estimator.get(modul_id, 0)
                }
                recommendations.append((modul_id, score.item(), module_detail))

        # Sort by similarity score
        recommendations.sort(key=lambda x: x[1], reverse=True)

        return recommendations[:top_k]

def get_learning_path(model: HGTModel, hetero_graph: HeteroGraph,
                     node_features: Dict[str, torch.Tensor]) -> List[Dict]:
    """Generate learning path based on prerequisites and difficulty"""
    model.eval()

    with torch.no_grad():
        embeddings = model(hetero_graph, node_features)

        if 'modul' not in embeddings:
            return []

        modul_nodes = hetero_graph.nodes['modul']
        modul_embs = embeddings['modul']
        modul_dict = {row[0]: row for row in modul_data}

        # Analyze learning path
        learning_path = []
        for i, modul_id in enumerate(modul_nodes):
            if modul_id in modul_dict:
                modul_info = modul_dict[modul_id]

                # Check prerequisites
                prerequisites = []
                for edge_data in hetero_graph.edges['prasyarat']:
                    src_type, src_idx, dst_type, dst_idx = edge_data
                    if dst_type == 'modul' and dst_idx == i and src_type == 'modul':
                        prereq_modul = modul_nodes[src_idx]
                        prerequisites.append(prereq_modul)

                # Calculate readiness score based on prerequisites
                readiness_score = 0
                if prerequisites:
                    prereq_scores = [knowledge.get(prereq, 0) for prereq in prerequisites]
                    readiness_score = np.mean(prereq_scores)
                else:
                    readiness_score = 1.0  # No prerequisites

                learning_path.append({
                    'modul_id': modul_id,
                    'nama': modul_info[1],
                    'kelas': modul_info[3],
                    'level_kesulitan': modul_info[2],
                    'prerequisites': prerequisites,
                    'readiness_score': readiness_score,
                    'current_knowledge': knowledge.get(modul_id, 0),
                    'difficulty_embedding': torch.norm(modul_embs[i]).item()
                })

        # Sort by readiness score and class level
        learning_path.sort(key=lambda x: (-x['readiness_score'], x['kelas'], x['level_kesulitan']))

        return learning_path

def generate_biologi_recommendations(top_k: int = 10):
    """Generate comprehensive biology module recommendations"""
    print("="*60)
    print("SISTEM REKOMENDASI MODUL BIOLOGI DENGAN HGT")
    print("="*60)

    # Train model
    model, hetero_graph, node_features = train_hgt_model(G, epochs=100)

    print("\n" + "="*50)
    print("REKOMENDASI MODUL BERDASARKAN PROFIL SISWA")
    print("="*50)

    # Get recommendations
    recommendations = get_module_recommendations(model, hetero_graph, node_features, top_k)

    for i, (modul_id, score, details) in enumerate(recommendations, 1):
        print(f"\n{i}. {details['nama']} ({modul_id})")
        print(f"   Kelas: {details['kelas']} | Level Kesulitan: {details['level_kesulitan']}")
        print(f"   Similarity Score: {score:.4f}")
        print(f"   Knowledge Score: {details['knowledge_score']:.3f}")
        print(f"   Performance: {details['performance_score']:.3f}")
        print(f"   Self-Estimation: {details['estimation_score']:.3f}")
        print(f"   Deskripsi: {details['deskripsi']}")

        # Recommendation reason
        if details['knowledge_score'] < 0.5:
            reason = "Perlu diperkuat - knowledge score rendah"
        elif details['performance_score'] < 0.4:
            reason = "Butuh latihan tambahan - performance rendah"
        elif score > 0.7:
            reason = "Sangat cocok dengan profil belajar Anda"
        else:
            reason = "Sesuai untuk pembelajaran lanjutan"
        print(f"   Rekomendasi: {reason}")

    print("\n" + "="*50)
    print("JALUR PEMBELAJARAN YANG DISARANKAN")
    print("="*50)

    # Get learning path
    learning_path = get_learning_path(model, hetero_graph, node_features)

    print("\nUrutan pembelajaran berdasarkan kesiapan dan prasyarat:")
    for i, path_item in enumerate(learning_path[:15], 1):  # Top 15
        print(f"\n{i}. {path_item['nama']} ({path_item['modul_id']})")
        print(f"   Kelas: {path_item['kelas']} | Level: {path_item['level_kesulitan']}")
        print(f"   Readiness Score: {path_item['readiness_score']:.3f}")
        print(f"   Current Knowledge: {path_item['current_knowledge']:.3f}")

        if path_item['prerequisites']:
            print(f"   Prerequisites: {', '.join(path_item['prerequisites'])}")
            # Check if prerequisites are met
            prereq_met = all(knowledge.get(p, 0) > 0.6 for p in path_item['prerequisites'])
            status = "âœ“ Ready" if prereq_met else "âš  Prerequisites needed"
            print(f"   Status: {status}")
        else:
            print(f"   Prerequisites: None (Entry level)")
            print(f"   Status: âœ“ Ready to start")

    return {
        'recommendations': recommendations,
        'learning_path': learning_path,
        'model': model,
        'graph': hetero_graph
    }

# Generate recommendations
results = generate_biologi_recommendations(top_k=10)